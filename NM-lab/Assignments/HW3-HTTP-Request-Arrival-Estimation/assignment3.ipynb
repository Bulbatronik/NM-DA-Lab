{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgRb4mQBd2UY"
      },
      "source": [
        "#**Homework**\n",
        "\n",
        "Complete the following tasks:\n",
        "\n",
        "* Use a dataset of 21 Video Sessions\n",
        "* Recognize the Video Server(s) IP and select video traffic (***if more than one Server is found, keep the dominant flow only***)\n",
        "* Detect Video Client HTTP Requests (Uplink packets with size larger or equal to 100 Bytes)\n",
        "* Compute features to predict:\n",
        " 1.   When the next UL Request is sent by the Video Client\n",
        " 2.   How large is the response of the Server to the next UL Request\n",
        "\n",
        "**N.B.**: Below, you can find a list of useful functions for the tasks at hand (introduced during class)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLyneRvWbkIk"
      },
      "source": [
        "The first thing is to import the needed libraries and mount the folder with the data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJxa-o59dwkB",
        "outputId": "9e331286-1414-4b53-cd8b-fa7f4f221598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/Network measurements /Captures_HW3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Network measurements /Captures_HW3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DsJgewH_DVk"
      },
      "source": [
        "### Functions Ready-To-Use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7niKjgZYbzXO"
      },
      "source": [
        "Set of predefined functions, same application as the ones discussed during the class. They were not modified and used as provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EKk7Xqfd6gI"
      },
      "outputs": [],
      "source": [
        "def filter_traffic(data, domain):\n",
        "    # Look in DNS Responses for googlevideo domain\n",
        "    dns_data = data[data['Protocol']=='DNS']\n",
        "    dns = dns_data[dns_data['Info'].apply(lambda x: 'googlevideo' in x and 'response' in x)]\n",
        "    ips = dns.Address.values\n",
        "    server_names = dns.Name.values\n",
        "\n",
        "    # Filtering on either \"Source\" or \"Destination\" IP, get the\n",
        "    # rows of the dataset that contain at least one of the selected IPs\n",
        "    downlink = data[data['Source'].apply(lambda x: x in ips)].dropna(subset=['Length'])\n",
        "    uplink = data[data['Destination'].apply(lambda x: x in ips)].dropna(subset=['Length'])\n",
        "    return ips, server_names, uplink, downlink\n",
        "\n",
        "def find_dominant(uplink, downlink):\n",
        "  # Expressed in MB\n",
        "  # Order flows by cumulative DL Volume\n",
        "  flows_DL = downlink.groupby(['Source','Destination'])['Length'].sum()/(10**6)\n",
        "\n",
        "  # Get (Source,Destination) IPs of dominant flows\n",
        "  dom_id = flows_DL[flows_DL==max(flows_DL)].index[0]\n",
        "\n",
        "  # Filter traffic selecting the dominant flow\n",
        "  dom_dl = downlink[downlink['Source']==dom_id[0]]\n",
        "  dom_ul = uplink[(uplink['Source']==dom_id[1])]\n",
        "  return dom_ul, dom_dl\n",
        "\n",
        "def timebased_filter(data, length=None, min_time=None, max_time=None):\n",
        "  '''\n",
        "  :param data: pd dataframe to be filtered. Must contain columns: \"Length\" and \"Time\"\n",
        "  :param length: all packets shorter than length [Bytes] will be discarded (default 0)\n",
        "  :param min_time: all packets with timestamp smaller than min_time [s] will be discarded (default 0)\n",
        "  :param max_time: all packets with timestamp larger than max_time [s] will be discarded (default 1000)\n",
        "  '''\n",
        "\n",
        "  if length is None:\n",
        "    length=0\n",
        "  if min_time is None:\n",
        "    min_time = 0\n",
        "  if max_time is None:\n",
        "    max_time = 1000\n",
        "\n",
        "  filtered_data = data.copy().reset_index()\n",
        "  mask = (filtered_data['Length']>=length) & (filtered_data['Time']>=min_time) & (filtered_data['Time']<= max_time)\n",
        "  filtered_data = filtered_data.loc[mask[mask ==True].index]\n",
        "  return filtered_data\n",
        "\n",
        "def find_next(array, value):\n",
        "  '''\n",
        "  :param array: np.array, array of floats\n",
        "  :param value: float, reference value\n",
        "  :return: position of the closest element of the array greater than \"value\"\n",
        "  '''\n",
        "  delta = np.asarray(array) - value\n",
        "  idx = np.where(delta >= 0, delta, np.inf).argmin()\n",
        "  return idx\n",
        "\n",
        "def normalize_dataset(training_set, test_set):\n",
        "  mean_train = training_set.mean()\n",
        "  std_train = training_set.std()\n",
        "  norm_train = (training_set - mean_train)/std_train\n",
        "  norm_test = (test_set - mean_train)/std_train\n",
        "  return norm_train, norm_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7ESTmG-b__l"
      },
      "source": [
        "This is a new function. Since the arrival time of next\n",
        "HTTP Request is the time between the last downlik packet and the next uplink packet, I use this function to find the index of the largest timstamp in the downlink which has a smaller value than the a timestamp of an uplink packet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCsgOrvg8qpH"
      },
      "outputs": [],
      "source": [
        "# Useful function\n",
        "def find_previous(array, value): # similarly to \"find_next\", this function returns te closest smaller value to the given one\n",
        "  '''\n",
        "  :param array: np.array, array of floats\n",
        "  :param value: float, reference value\n",
        "  :return: position of the closest element of the array smaller than \"value\"\n",
        "  '''\n",
        "  delta = np.asarray(array) - value\n",
        "  idx = np.where(delta <= 0, delta, -np.inf).argmax()\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMO_nFab_IPu"
      },
      "source": [
        "### Functions to be completed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdrKDHLof4ab"
      },
      "source": [
        "It is required to compute 'Next_Request_Time' and 'Next_Response_Vol' as the groundtuth values. 'Next_Response_Vol' can be easily taken from the 'DL_Vol' feature and assigning it's value to the previous grountruth. We will use 1:last values of 'DL_Vol' and assign them to 0:last-1 values of 'Next_Response_Vol'. For the 'Next_Request_Time', we take the uplink (discarding the first one) requests and for each one of them we find the last downlink using the function 'find_previous'. Then we use the difference in the timestamp as the corresponding label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi212kIMeIXr"
      },
      "outputs": [],
      "source": [
        "def features_extraction(uplink, downlink):\n",
        "  '''\n",
        "  Complete this function to extract both features and groundtruth.\n",
        "\n",
        "  NB: The features extraction process is the same as the one introduced during\n",
        "  the lecture.\n",
        "  '''\n",
        "  dataset = pd.DataFrame(columns=['Request_Size','Inter_RR_Time','DL_Time','DL_Vol','DL_Size','PB_Time'])\n",
        "  # ****************************************************************************\n",
        "  # Feature 1: Client Request Size\n",
        "  dataset['Request_Size'] = list(uplink.Length.values)\n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 2: Inter Request-Response Time\n",
        "  rr_time = []\n",
        "  response_time = []\n",
        "  for t in uplink.Time:\n",
        "    response_time.append(find_next(downlink.Time, t)) #index of next DL packet timestamp\n",
        "    rr_time.append(downlink.Time.iloc[response_time[-1]] - t)\n",
        "\n",
        "  dataset['Inter_RR_Time'] = rr_time\n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 3-4-5: Download Time, Download Volume, Download Size (# Packets)\n",
        "  dt = []\n",
        "  dv = []\n",
        "  ds = []\n",
        "\n",
        "  for rt1, rt2 in zip(response_time[:-1], response_time[1:]):\n",
        "    #Download Time\n",
        "    dt.append(downlink.Time.iloc[rt2-1] - downlink.Time.iloc[rt1])\n",
        "    temp = timebased_filter(downlink, 0, downlink.Time.iloc[rt1], downlink.Time.iloc[rt2-1])\n",
        "\n",
        "    #Download Volume\n",
        "    dv.append(temp.Length.sum())\n",
        "    \n",
        "    #Download Size (# Packets)\n",
        "    ds.append(temp.shape[0])\n",
        "\n",
        "  # Last Iteration data might be corrupted due to drastic interruption of capture\n",
        "  # process. If it is so, an error would occur during the features extraction.\n",
        "  # To avoid this, we skip last HTTP iteration data when an error is raised\n",
        "  # using the try-except logic below.\n",
        "  try:\n",
        "    # Consider also last HTTP iteration\n",
        "    # Download Time\n",
        "    dt.append(downlink.Time.iloc[-1] - downlink.Time.iloc[rt2])\n",
        "\n",
        "    temp = timebased_filter(downlink, 0, downlink.Time.iloc[rt2], downlink.Time.iloc[-1])\n",
        "    # Download Volume\n",
        "    dv.append(temp.Length.sum())\n",
        "\n",
        "    # Download Size (# Packets)\n",
        "    ds.append(temp.shape[0])\n",
        "  except:\n",
        "    print()\n",
        "\n",
        "  dataset['DL_Time'] = dt\n",
        "  dataset['DL_Vol'] = dv\n",
        "  dataset['DL_Size'] = ds\n",
        "\n",
        "  # ****************************************************************************\n",
        "  # Feature 5: Playback Time\n",
        "  pbt = list(uplink.Time.values)\n",
        "  dataset['PB_Time'] = pbt\n",
        "  # ****************************************************************************\n",
        "\n",
        "\n",
        "  # Check Features Consistency\n",
        "  dataset = dataset[(dataset > 0).all(1)]\n",
        "  dataset = dataset[dataset['DL_Time']<20]\n",
        "\n",
        "  ###############################################################\n",
        "  # TO BE COMPLETED\n",
        "\n",
        "  ### EXTRACT GROUNDTRUTH HERE\n",
        "  groundtruth = pd.DataFrame(columns=['Next_Request_Time','Next_Response_Vol'])\n",
        "  # ****************************************************************************\n",
        "  # GT 1: Next Request Time\n",
        "\n",
        "  Next_Request_Time = []\n",
        "\n",
        "  for t in uplink.Time:\n",
        "    # difference between the large uplink packet and the closest previous downlink\n",
        "    Next_Request_Time.append(t - downlink.Time.iloc[find_previous(downlink.Time, t)])\n",
        "\n",
        "  groundtruth['Next_Request_Time'] = Next_Request_Time\n",
        "\n",
        "  # the first uplink doesn't have downlink before -> time will be negative -> discard\n",
        "  groundtruth = groundtruth[(groundtruth['Next_Request_Time'] > 0)]\n",
        "  # ****************************************************************************\n",
        "  # GT 2: Next Response Volume\n",
        "  \n",
        "  # basically, the feature of the next sample (starting from the 2nd)\n",
        "  next_resp_vol = dataset['DL_Vol'].iloc[1:]\n",
        "  # but for the assignment, we will start from the first index, ignore the last row (can't extract the label for it)\n",
        "  ind_list = list(dataset['DL_Vol'].iloc[:-1].index)\n",
        "  # swap indexes\n",
        "  next_resp_vol.index = ind_list \n",
        "  groundtruth['Next_Response_Vol'] =  next_resp_vol\n",
        "\n",
        "  ###############################################################\n",
        "\n",
        "  # Check Ground Truth Consistency\n",
        "  groundtruth.dropna(inplace=True)\n",
        "\n",
        "  # Align Dataset and Groundtruth\n",
        "  intersection = set(dataset.index).intersection(set(groundtruth.index))\n",
        "  dataset = dataset.loc[intersection,:]\n",
        "  groundtruth = groundtruth.loc[intersection,:]\n",
        "  return dataset, groundtruth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45P-M-v_PKm"
      },
      "source": [
        "### Write your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLQx9pqziYue"
      },
      "source": [
        "Now we will loop over each of the files in the folder, read it, extract the uplink and dounlink and filter the uplink to get the 'large' packet (nothing is specified for the upling and the playback start, therefore it is not filtered). Then we extract the predefined features and the acquired groundtruth from the dounlink and filtered uplink are append them to the global dataset. Then we visualize several rows of the datasets to check the consistecy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBM3TkVZ50WF"
      },
      "outputs": [],
      "source": [
        "# initialize the dataframes\n",
        "data = pd.DataFrame()\n",
        "ground = pd.DataFrame()\n",
        "\n",
        "# Filter UL/DL Data\n",
        "\n",
        "playback_start = 0 #sec\n",
        "playback_end = 180 #sec (after -> discard)\n",
        "min_ul_size = 100 #bytes\n",
        "min_dl_size = 0 #bytes\n",
        "\n",
        "for file_name in os.listdir():# for each file in the folder\n",
        "    df = pd.read_csv(file_name) # read the file\n",
        "\n",
        "    _, _, uplink, downlink = filter_traffic(df, 'googlevideo')# extract the uplink and the downlink\n",
        "\n",
        "    dom_ul, dom_dl = find_dominant(uplink, downlink)# find the dominant up- and downlinks\n",
        "\n",
        "    # filter the uplink to get packets with the length at least 'min_ul_size' bytes\n",
        "    dom_ul = timebased_filter(dom_ul, min_ul_size, playback_start, playback_end)\n",
        "    dom_dl = timebased_filter(dom_dl, min_dl_size, playback_start, playback_end)# NOT FILTERED, SINCE NOT REQUIRED BY THE TASK\n",
        "\n",
        "    dataset, groundtruth = features_extraction(dom_ul, dom_dl)# extract the features and the ground truth\n",
        "\n",
        "    # append everything in the global datafframe\n",
        "    data = data.append(dataset, ignore_index = True)\n",
        "    ground = ground.append(groundtruth, ignore_index = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEsbRLs_jaqo"
      },
      "source": [
        "Short consistency analysis of the data (features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OiYDBJgHBgRe",
        "outputId": "828e580f-a70a-46ff-80ef-55c4b6fb432b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ac0bef66-b7e5-4669-ad2a-35ba156714ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Request_Size</th>\n",
              "      <th>Inter_RR_Time</th>\n",
              "      <th>DL_Time</th>\n",
              "      <th>DL_Vol</th>\n",
              "      <th>DL_Size</th>\n",
              "      <th>PB_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>661</td>\n",
              "      <td>0.003477</td>\n",
              "      <td>0.035957</td>\n",
              "      <td>1493386</td>\n",
              "      <td>989</td>\n",
              "      <td>0.542976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>661</td>\n",
              "      <td>0.010791</td>\n",
              "      <td>0.013774</td>\n",
              "      <td>509484</td>\n",
              "      <td>338</td>\n",
              "      <td>5.540538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>661</td>\n",
              "      <td>0.009317</td>\n",
              "      <td>0.026510</td>\n",
              "      <td>1018662</td>\n",
              "      <td>675</td>\n",
              "      <td>11.552147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>661</td>\n",
              "      <td>0.010225</td>\n",
              "      <td>0.027004</td>\n",
              "      <td>1008818</td>\n",
              "      <td>669</td>\n",
              "      <td>16.561117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>661</td>\n",
              "      <td>0.009692</td>\n",
              "      <td>0.014666</td>\n",
              "      <td>510478</td>\n",
              "      <td>339</td>\n",
              "      <td>21.575435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac0bef66-b7e5-4669-ad2a-35ba156714ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac0bef66-b7e5-4669-ad2a-35ba156714ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac0bef66-b7e5-4669-ad2a-35ba156714ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Request_Size  Inter_RR_Time   DL_Time   DL_Vol  DL_Size    PB_Time\n",
              "0           661       0.003477  0.035957  1493386      989   0.542976\n",
              "1           661       0.010791  0.013774   509484      338   5.540538\n",
              "2           661       0.009317  0.026510  1018662      675  11.552147\n",
              "3           661       0.010225  0.027004  1008818      669  16.561117\n",
              "4           661       0.009692  0.014666   510478      339  21.575435"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuk9CvDLjmtQ"
      },
      "source": [
        "Short consistency analysis of the groundtruth (labels). We see that the 'Next_Response_Vol' of the ith sample corresponds to the 'DL_Vol' of the next row in 'data'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7u_SUqyOm9h9",
        "outputId": "d75978bf-446a-43f0-c945-172a8cb68e33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a5db1e97-6709-40a0-9189-eda1457f1537\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Next_Request_Time</th>\n",
              "      <th>Next_Response_Vol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.004185</td>\n",
              "      <td>509484.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.958128</td>\n",
              "      <td>1018662.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.987044</td>\n",
              "      <td>1008818.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.973143</td>\n",
              "      <td>510478.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.977089</td>\n",
              "      <td>521404.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5db1e97-6709-40a0-9189-eda1457f1537')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5db1e97-6709-40a0-9189-eda1457f1537 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5db1e97-6709-40a0-9189-eda1457f1537');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Next_Request_Time  Next_Response_Vol\n",
              "0           0.004185           509484.0\n",
              "1           4.958128          1018662.0\n",
              "2           5.987044          1008818.0\n",
              "3           4.973143           510478.0\n",
              "4           4.977089           521404.0"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYzUTO7xkCrE"
      },
      "source": [
        "Now we will apply two random forest regressors for each of the label independently to predict 'Next_Response_Vol' and 'Next_Response_Time'. We also use 10-fold CV to get a performance value with a larger suppurt as well as a standard deviation for each of the RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtHrJZp6tueU",
        "outputId": "7e480c29-98c4-47a9-a128-f479f8982f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE of the arrival time of next HTTP Request = : 5.44 [s] (std = 2.37)\n",
            "\n",
            "RMSE of the size of next burst from the servert = : 350.45 [KB] (std = 123.22)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10)# 10-fold CV\n",
        "\n",
        "# lists to keep track of the performance (RMSE)\n",
        "RMSE_time = []\n",
        "RMSE_volume = []\n",
        "\n",
        "for train_index, test_index in kf.split(data):\n",
        "    data_train, data_test = data.iloc[train_index,:], data.iloc[test_index,:] # get the train data\n",
        "\n",
        "    labels_train_time, labels_test_time = ground['Next_Request_Time'].iloc[train_index], ground['Next_Request_Time'].iloc[test_index]# get the time labels\n",
        "    labels_train_volume, labels_test_volume = ground['Next_Response_Vol'].iloc[train_index], ground['Next_Response_Vol'].iloc[test_index]# get the volume labels\n",
        "\n",
        "    norm_train, norm_test = normalize_dataset(data_train, data_test)\n",
        "\n",
        "    # regressor for the arrival time of next HTTP Request\n",
        "    rf_reg_time = RandomForestRegressor()\n",
        "    rf_reg_time.fit(norm_train, labels_train_time)# fit the regressor on the data-time labels\n",
        "    prediction_rf_time = rf_reg_time.predict(norm_test)\n",
        "\n",
        "    # regressor for the size of next burst from the server\n",
        "    rf_reg_volume = RandomForestRegressor()\n",
        "    rf_reg_volume.fit(norm_train, labels_train_volume)# fit the regressor on the data-volume labels\n",
        "    prediction_rf_volume = rf_reg_volume.predict(norm_test)\n",
        "\n",
        "    # compute the RMSEs from the available MSE maetric\n",
        "    RMSE_time.append(np.sqrt(metrics.mean_squared_error(labels_test_time, prediction_rf_time)))\n",
        "    RMSE_volume.append(np.sqrt(metrics.mean_squared_error(labels_test_volume, prediction_rf_volume)))\n",
        "\n",
        "print(\"RMSE of the arrival time of next HTTP Request = : {:.2f} [s] (std = {:.2f})\\n\".format(np.mean(RMSE_time), np.std(RMSE_time)))\n",
        "print(\"RMSE of the size of next burst from the servert = : {:.2f} [KB] (std = {:.2f})\\n\".format(np.mean(RMSE_volume)/10**3, np.std(RMSE_volume)/10**3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r7oomvxlphN"
      },
      "source": [
        "The results are consistent with the one provided as a suggested reference in the presentation. That depends on the data partitioning and the sample in the train and test sets, but overall the results are adequate."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
