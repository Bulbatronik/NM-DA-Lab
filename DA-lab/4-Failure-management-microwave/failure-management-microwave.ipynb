{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn.metrics as mt\n",
    "import hyperopt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "#Additional packages for the clustering part\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1a) \n",
    "Load data from *Labelled_Multiclass.csv* in pandas dataframe, delete unnecessary info (idlink, eqtype, acmLowerMode, freqband, bandwidth), and visualize it in tabular form \n",
    "\n",
    "Hint:\n",
    "- *Pandas* guide at: https://pandas.pydata.org/docs/user_guide/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('Labelled_Multiclass.csv')\n",
    "\n",
    "# F: use another pandas dataframe \"data\" to store the new dataframe where you have dropped unnecessary columns\n",
    "\n",
    "############# ADD YOUR CODE BELOW #############\n",
    "\n",
    "columns = raw_data.columns.to_numpy()\n",
    "\n",
    "# delete the first 8 columns\n",
    "data = raw_data.drop(columns=columns[:8])\n",
    "\n",
    "#print(data.iloc[2,:])\n",
    "#print(data.to_numpy()[2,:]) #F: same as print(data.iloc[2,:].to_numpy())\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1b) \n",
    "Define function *plot_feature()* that takes in input dataframe and feature number (passed as integer representing the column index), and plots the distribution of the feature. Distribution should be plotted as histograms and boxplot\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(dataframe,featurenumber=0):\n",
    "    feature = dataframe.iloc[:,featurenumber].to_numpy() #F: this way it is a numpy.ndarray\n",
    "    print('You are going to see feature {}: {}'.format(featurenumber,dataframe.columns.values[featurenumber]))\n",
    "    minvalue = feature.min()\n",
    "    maxvalue = feature.max()\n",
    "    \n",
    "    plt.hist(feature, bins = 1 + int(maxvalue-minvalue))\n",
    "    plt.xlabel(dataframe.columns.values[featurenumber])\n",
    "    plt.ylabel('No. of occurrences')\n",
    "    fig_hist = plt.gcf()\n",
    "    plt.show()\n",
    "    \n",
    "    allbox = []\n",
    "    \n",
    "    #F: boxplot of the feature passed as input param\n",
    "    dataframe.iloc[:,featurenumber].plot(kind='box', subplots=True, sharex=False, sharey=False)\n",
    "    fig_box = plt.gcf()\n",
    "    plt.show()\n",
    "    \n",
    "    #F: boxplot of all the features in the same graph\n",
    "    #dataframe.iloc[:,0:len(dataframe.columns)].plot(kind='box', subplots=False, sharex=False, sharey=False)\n",
    "    #plt.xticks(rotation=90)\n",
    "    #fig_allbox = plt.gcf()\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    #F: in case you want to save figures in a dedicated folder\n",
    "    #res_folder = 'Figs_features'\n",
    "    #if not os.path.exists(res_folder):\n",
    "    #    os.makedirs(res_folder)\n",
    "    #\n",
    "    #fig_hist.savefig(res_folder + '\\Feature_{}_hist.png'.format(dataframe.columns.values[featurenumber]))\n",
    "    #fig_box.savefig(res_folder + '\\Feature_{}_boxplot.png'.format(dataframe.columns.values[featurenumber]))\n",
    "    ##fig_allbox.savefig(res_folder + '\\All-features_boxplot.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1c)\n",
    "Call function *plot_feature()* to plot features no. 2 and 4\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature(data,2)\n",
    "\n",
    "plot_feature(data,4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we observe? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1d) \n",
    "Check which features have missing values. Then, ONLY FOR THOSE FEATURES, use function *plot_feature()* from task 1b) to plot the distribution neglecting missing values\n",
    "\n",
    "If everything is ok in your code, you should find 24 features with NaN values. \n",
    "### Anything in common between these 24 features? \n",
    "\n",
    "Hints: \n",
    "- To plot each feature, you can use a support temporary dataframe extracting one column at a time from the original loaded dataframe\n",
    "- Use *isnull* and *dropna* from *pandas* to find and drop NaN:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.isnull.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = raw_data.columns.to_numpy()\n",
    "data = raw_data.drop(columns=columns[:8]) #F: this line (repeated from a previous cell) re-loads data with nan, thus prevents the case of not being able to find Nans (in case you run this cell multiple times)\n",
    "featureswithnan = 0 #F: this is supposed to count the number of features with nan\n",
    "############# ADD YOUR CODE BELOW #############\n",
    "\n",
    "\n",
    "for i in range(len(data.columns.values)):\n",
    "    tempdata=data.iloc[:,i] #F: tempdata is now a pandas.Series \n",
    "    tempdata=tempdata.to_frame() #F: need to convert pandas.Series into dataframe to pass it into function plot_feature() above, due to indexing error in that function otherwise\n",
    "    # ---------------------------------------------------------\n",
    "    # Find indexes of cells with Nan\n",
    "    nanindexes=np.where(pd.isnull(tempdata))\n",
    "    #print(nanindexes)\n",
    "    #print(len(np.where(pd.isnull(raw_data))[0])) #rows\n",
    "    #print(len(np.where(pd.isnull(raw_data))[1])) #columns\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # Find indexes of empty cells \n",
    "    #emptyindexes=np.where(data.applymap(lambda x: x == ''))\n",
    "    \n",
    "    if len(nanindexes[0])!=0:\n",
    "        featureswithnan += 1\n",
    "        print('Feature {} has Nan. We are going to remove Nan and plot the feature distribution.'.format(tempdata.columns.values[0]))\n",
    "        tempdata.dropna(inplace=True)\n",
    "        #tempdata.drop(tempdata[tempdata[tempdata.columns.values[0]]=='18'].index, inplace=True) #F: use this if you want to drop a row with a specific value (e.g., =18) \n",
    "        plot_feature(tempdata,)\n",
    "\n",
    "#################################################\n",
    "print('*********************************')\n",
    "print('We found {} features with NaN values'.format(featureswithnan))        \n",
    "print('*********************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1e) \n",
    "Take features with missing values and substitute NaN with the median of the feature without NaN. Print the features and corresponding median values used to replace NaN values\n",
    "\n",
    "Hint: \n",
    "- *median(skipna=True)* from *Pandas* calculates median on dataframes neglecting Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.drop(columns=columns[:8]) #F: this line re-loads data with nan, thus prevents errors (not being able to find Nans) in case you run this cell multiple times\n",
    "\n",
    "nanindexes=np.where(pd.isnull(data)) # store indexes where data has nan values\n",
    "\n",
    "for i in np.unique(nanindexes[1]): #F: scan all columns where we have nan \n",
    "    # np.unique finds the unique (i.e., wothout repetitions) elements of an array \n",
    "    # \"[1]\" so we focus on the columns (i.e., the features)\n",
    "    \n",
    "    # For each feature i you should replace its Nan values with median of the valid values of the feature\n",
    "    ############# ADD YOUR CODE BELOW #############\n",
    "\n",
    "    tempdata = data.iloc[:,i] #F: extracts the i-th column from data, where i is one of the column with nan\n",
    "    median = tempdata.median(skipna=True) #F: calculate median for this column neglecting Nan\n",
    "    print('{}, median ={}'.format(data.columns.values[i],median))\n",
    "    data[data.columns.values[i]] = data[data.columns.values[i]].fillna(median) #F: insert the median in the dataset\n",
    "\n",
    "    \n",
    "#############################################################################\n",
    "#Following lines verify that nan in data have been replaced\n",
    "#if nanindex turns out to be an array with empty elements --> OK\n",
    "#if necessary, change \"data\" with the name of your dataframe to make it work\n",
    "nanindexes = np.where(pd.isnull(data))\n",
    "nanindexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2a) \n",
    "Define function *load_dataset()* to load a dataset from a given dataframe in input into given arrays X and y passed in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(X, y, dataset):\n",
    "#Inputs: - X: (numpy array) features retrieved from dataset\n",
    "#        - y: (numpy array) labels retrieved from dataset\n",
    "#        - dataset: dataframe with data points to be read (it must be a dataset without unnecessary features as created above)\n",
    "#This function should load into X and y in input the datapoints retrieved from dataset and return X and y\n",
    "############# ADD YOUR CODE BELOW #############\n",
    "\n",
    "    X = dataset.iloc[:,0:-1].to_numpy()\n",
    "    y = dataset.iloc[:,-1].to_numpy()\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2b)\n",
    "Test function *load_dataset()* with datasets created in task 1e)\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should pass empty X and y to function load_window_dataset\n",
    "X=None \n",
    "y=None\n",
    "\n",
    "X, y = load_dataset(X, y, data)\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3a) \n",
    "Standardize features, split dataset into train/test (80% / 20%) with balanced classes, and print shapes of train and test sets\n",
    "\n",
    "Hints: \n",
    "- use *StandardScaler()* from *sklearn.preprocessing* and *train_test_split* from *sklearn.model_selection* \n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage = 0.2  # Percentage of points included in the test dataset (e.g., 20% = 0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# -------------------- Scale the data (Manually) --------------------\n",
    "# mean_X = np.mean(X, axis=0)  # Mean per feature of the training data\n",
    "# std_tX = np.std(X, axis=0)  # Std per feature of the training data\n",
    "# X = (X - mean_X) / std_X  # Scaling training data\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percentage,\n",
    "                                                    random_state=42, stratify=y)\n",
    "\n",
    "#print(X_train)\n",
    "#print(X_test)\n",
    "#print(y_train)\n",
    "#print(y_test)\n",
    "print('Training set shape (features): {}'.format(X_train.shape))\n",
    "print('Training set shape (labels): {}'.format(y_train.shape))\n",
    "print('Test set shape (features): {}'.format(X_test.shape))\n",
    "print('Test set shape (labels): {}'.format(y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3b)\n",
    "Define function *optimize_RF()* that performs hyperparameter optimization with 5-fold crossvalidation, retrains the model on the entire training set with the optimized hyperparameters and returns the trained model (details below).\n",
    "\n",
    "Hints: \n",
    "- use *hyperopt* library to perform hyperparameters optimization: http://hyperopt.github.io/hyperopt/\n",
    "- use *RandomForestClassifier from sklearn.ensemble* for the RF model: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "- use *cross_val_score* as a metric to determine the best hyperparameters: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_RF(X_train, y_train): \n",
    "#Inputs: - X_train: training set (features)\n",
    "#        - y_train: training set (ground truth labels)\n",
    "#\n",
    "#Output: - rf: model to be returned by the function\n",
    "#\n",
    "#This function should: \n",
    "#         * Perform RF hyperparameters optimization via crossvalidation\n",
    "#         * Print best hyperparameters obtained with crossvalidation\n",
    "#         * Print best crossvalidation accuracy (across all hyperparameters combinations) and duration\n",
    "#         * Retrain a new RF model with best hyperparameters using the entire training set (X_train, y_train)\n",
    "#         * Print training results (best accuracy and training duration)\n",
    "#         * Return the trained RF model\n",
    "\n",
    "    #F: define the search space for your hyperparameters\n",
    "    space4rf = { \n",
    "     'estimators': hp.choice('estimators', [10, 50, 100, 200, 500]),\n",
    "     'crit': hp.choice('crit', ['gini', 'entropy', 'log_loss']),\n",
    "     'maxd': hp.choice('maxd', np.arange(1, 20, 2)),\n",
    "    }\n",
    "\n",
    "    def hyperopt_train_test(params):\n",
    "        model = RandomForestClassifier(n_estimators=params['estimators'], criterion=params['crit'],\n",
    "                                       max_depth=params['maxd'], class_weight='balanced')\n",
    "\n",
    "        return cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "        #F: cross_val_score is from scikit learn (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "        #F: will use the default score (for RF it is accuracy)\n",
    "        #F: this includes also training; cv=5 (5-folds crossvalidation)\n",
    "        #F: .mean() is taken as cross_val_score returns an array of scores (one for each fold)\n",
    "        \n",
    "    def f(params): #F: this function is used below, as a parameter to fmin\n",
    "        acc = hyperopt_train_test(params)\n",
    "        return {'loss': -acc, 'status': STATUS_OK} #F: loss is returned as opposite (negative) of accuracy because we will use in f_min (that only minimizes), where we want to minimize the loss (i.e., maximize accuracy)\n",
    "\n",
    "    trials = Trials() #F: an object that keeps track of all trials (i.e., combination of hyperparameters) tested during the optimization\n",
    "    \n",
    "    ta = time.time()\n",
    "    best_params = fmin(f, space4rf, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "    #F: see: https://github.com/hyperopt/hyperopt/blob/master/hyperopt/fmin.py\n",
    "    #F: at this point, best_param is a dictionary where each key is the index of the corresponding best param in space4rf\n",
    "    tb = time.time()\n",
    "    print(best_params)\n",
    "    \n",
    "    best_params = hyperopt.space_eval(space4rf, best_params)\n",
    "    #F: this is used to extract from space4rf the best values \n",
    "    #   according to the indexes in best_params (and put such values in best_params)\n",
    "    print(best_params)\n",
    "    \n",
    "    best_cv_acc = -round(trials.best_trial['result']['loss'], 2) #F: best across trials\n",
    "    print('best_cv_acc: ' + str(best_cv_acc))\n",
    "    print('Crossvalidation duration for RF is {} s\\n'.format(round(tb - ta)))\n",
    "\n",
    "    \n",
    "    #######################################################################################################\n",
    "    #F: Now you have best hyperparameters obtained with crossvalidation and should train a new model \n",
    "    #   using those hyperparameters and the entire training set; then return the trained model\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=best_params['estimators'], criterion=best_params['crit'],\n",
    "                                       max_depth=best_params['maxd'], class_weight='balanced')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    rf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('Best number of estimators: {}\\n'.format(best_params['estimators']))\n",
    "    print('Best splitting criterion: {}\\n'.format(best_params['crit']))\n",
    "    print('Best max_depth: {}\\n'.format(best_params['maxd']))\n",
    "    print('Crossvalidation accuracy: {}\\n'.format(best_cv_acc))\n",
    "    print('Training duration for RF is {} s\\n'.format(round(t1 - t0)))\n",
    "\n",
    "\n",
    "    return rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3c)\n",
    "Call function *optimize_RF()* and save the trained RF model in a .json file\n",
    "\n",
    "Hint:\n",
    "- Use pickle.dump to save models to disk\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training RF...')\n",
    "rf = optimize_RF(X_train, y_train)\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "        \n",
    "rfmodelfile = 'models\\RF.json'\n",
    "pickle.dump(rf, open(rfmodelfile, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3d)\n",
    "Define function *optimize_KNN()* that performs hyperparameter optimization with 5-fold crossvalidation, retrains the model on the entire training set with the optimized hyperparameters and returns the trained model (details below).\n",
    "\n",
    "Hints: \n",
    "- take inspiration from task 3b) on RF optiomization using *hyperopt* library\n",
    "- use *KNeighborsClassifier from sklearn.neighbors* for the KNN model: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_KNN(X_train, y_train): \n",
    "#Inputs: - X_train: training set (features)\n",
    "#        - y_train: training set (ground truth labels)\n",
    "#\n",
    "#Output: - knn: model to be returned by the function\n",
    "#\n",
    "#This function should: \n",
    "#         * Perform KNN hyperparameters optimization via crossvalidation\n",
    "#         * Print best hyperparameters obtained with crossvalidation\n",
    "#         * Print best crossvalidation accuracy (across all hyperparameters combinations) and duration\n",
    "#         * Retrain a new KNN model with best hyperparameters using the entire training set (X_train, y_train)\n",
    "#         * Print training results (best accuracy and training duration)\n",
    "#         * Return the trained KNN model\n",
    "\n",
    "    #F: define the search space for your hyperparameters\n",
    "    space4knn = { \n",
    "     'neighb': hp.choice('neighb', [1, 5, 10, 20, 50, 100]),\n",
    "     'wgts': hp.choice('wgts', ['uniform', 'distance']),\n",
    "    }\n",
    "    ############# ADD YOUR CODE BELOW #############\n",
    "\n",
    "\n",
    "    def hyperopt_train_test(params):\n",
    "        model = KNeighborsClassifier(n_neighbors=params['neighb'], weights=params['wgts'])\n",
    "\n",
    "        return cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "        #F: cross_val_score is from scikit learn (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "        #F: will use the default score (for KNN it is accuracy)\n",
    "        #F: this includes also training; cv=5 (5-folds crossvalidation)\n",
    "        #F: .mean() is taken as cross_val_score returns an array of scores (one for each fold)\n",
    "        \n",
    "    def f(params): #F: this function is used below, as a parameter to fmin\n",
    "        acc = hyperopt_train_test(params)\n",
    "        return {'loss': -acc, 'status': STATUS_OK} #F: loss is returned as opposite (negative) of accuracy because we will use in f_min (that only minimizes), where we want to minimize the loss (i.e., maximize accuracy)\n",
    "\n",
    "    trials = Trials()\n",
    "    ta = time.time()\n",
    "    best_params = fmin(f, space4knn, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "    tb = time.time()\n",
    "    print(best_params)\n",
    "    \n",
    "    best_params = hyperopt.space_eval(space4knn, best_params)\n",
    "    #F: this is used to extract from space4knn the best values according to the indexes in best_params (and put such values in best_params)\n",
    "    print(best_params)\n",
    "    \n",
    "    best_cv_acc = -round(trials.best_trial['result']['loss'], 2) #F: best across trials\n",
    "    print('best_cv_acc: ' + str(best_cv_acc))\n",
    "    print('Crossvalidation duration for KNN is {} s\\n'.format(round(tb - ta)))\n",
    "\n",
    "    #######################################################################################################\n",
    "    #F: Now you have best hyperparameters obtained with crossvalidation and should train a new model \n",
    "    #   using the entire training set using those hyperparameters and return the trained model\n",
    "    ############# ADD YOUR CODE BELOW #############\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=best_params['neighb'], weights=best_params['wgts'])\n",
    "    \n",
    "    t0 = time.time()\n",
    "    knn.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('Best number of neighbors: {}\\n'.format(best_params['neighb']))\n",
    "    print('Best weight function: {}\\n'.format(best_params['wgts']))\n",
    "    print('Crossvalidation accuracy: {}\\n'.format(best_cv_acc))\n",
    "    print('Training duration for KNN is {} s\\n'.format(round(t1 - t0)))\n",
    "\n",
    "\n",
    "    return knn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3e)\n",
    "Call function *optimize_KNN()* and save the trained KNN model in a .json file\n",
    "\n",
    "Hint:\n",
    "- See task 3c) for reference\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training KNN...')\n",
    "knn = optimize_KNN(X_train, y_train)\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "        \n",
    "knnmodelfile = 'models\\KNN.json'\n",
    "pickle.dump(knn, open(knnmodelfile, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4a)\n",
    "Define function *performance_eval()* that takes in input ground truth and predicted labels, prints results in output, and returns PER-CLASS metrics (details below)\n",
    "**N.B. Metrics should be calculated \"manually\" (applying the specific formulae) AND with sklearn APIs**\n",
    "\n",
    "Hint: \n",
    "- *confusion_matrix* and other metrics from *sklearn.metrics* can be used to compute metrics via APIs\n",
    "- parameter *average=None* is used to calculate unweighted metrics using sklearn APIs\n",
    "- you can use pandas dataframes to calculate metrics \"manually\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_eval(y_true, y_pred, l_names):\n",
    "# Inputs: - y_true: ground truth labels\n",
    "#         - y_pred: predicted labels\n",
    "#         - l_names: labels used in the problem at hand (e.g., 0,1,2,3,4,5)\n",
    "# Outputs: - return accuracy, precision, recall, f1score\n",
    "# This function should: \n",
    "#         - Compute Accuracy, Precision (per class), Recall (per class), F1-score (per class). \n",
    "#         - Metrics should be calculated \"manually\" (applying the specific formulae) AND with sklearn APIs\n",
    "#         - Compute confusion matrix (cm)\n",
    "#         - Print metrics and cm in output (already given below)\n",
    "#         - Return Accuracy, Precision, Recall, F1-score (note that the last 3 metrics are per-class) (already given below)\n",
    "#         - Draw the confusion matrix (already given in the code, you need to call the confusion matrix object as cm)\n",
    "    vectors = pd.DataFrame()\n",
    "    vectors['ground_truth'] = y_test\n",
    "    vectors['predicted'] = y_pred\n",
    "    \n",
    "    num_labels = len(set(l_names))\n",
    "    \n",
    "    # Metrics calculated with sklearn APIs\n",
    "    accuracy = mt.accuracy_score(y_true, y_pred)\n",
    "    precision = mt.precision_score(y_true, y_pred, labels=l_names, average=None) #F: average=None gives per-class results\n",
    "    recall = mt.recall_score(y_true, y_pred, labels=l_names, average=None)\n",
    "    f1score = mt.f1_score(y_true, y_pred, labels=l_names, average=None)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    #F: init\n",
    "    man_accuracy = 0\n",
    "    man_precision = np.zeros(num_labels)\n",
    "    man_recall = np.zeros(num_labels)\n",
    "    man_f1score = np.zeros(num_labels)\n",
    "    \n",
    "    # Now you should compute \"manually\" (applying the specific formulae)\n",
    "    ############# ADD YOUR CODE BELOW #############\n",
    "    \n",
    "    # ------------ accuracy ------------\n",
    "    man_accuracy = len(vectors.loc[vectors['ground_truth'] == vectors['predicted']]) / len(vectors)\n",
    "    \n",
    "    # ------------ precision ------------\n",
    "    for i in range(num_labels):\n",
    "        measure = pd.DataFrame()\n",
    "        measure['ground_truth'] = vectors.loc[vectors['predicted'] == i]['ground_truth']\n",
    "        measure['predicted'] = vectors.loc[vectors['predicted'] == i]['predicted']\n",
    "        man_precision[i] = len(measure.loc[measure['ground_truth'] == measure['predicted']]) / len(measure)\n",
    "\n",
    "    # ------------ recall ------------\n",
    "    for i in range(num_labels):\n",
    "        measure = pd.DataFrame()\n",
    "        measure['ground_truth'] = vectors.loc[vectors['ground_truth'] == i]['ground_truth']\n",
    "        measure['predicted'] = vectors.loc[vectors['ground_truth'] == i]['predicted']\n",
    "        man_recall[i] = len(measure.loc[measure['ground_truth'] == measure['predicted']]) / len(measure)\n",
    "\n",
    "    # ------------ F1-score ------------\n",
    "    for i in range(num_labels):\n",
    "        man_f1score[i] = 2 * (man_precision[i] * man_recall[i]) / (man_precision[i] + man_recall[i])\n",
    "\n",
    "        \n",
    "    ########################################################################\n",
    "    print('Accuracy: {}'.format(accuracy))\n",
    "    print('Manual accuracy: {}'.format(man_accuracy))\n",
    "\n",
    "    print('Precision per class: {}'.format(precision))\n",
    "    print('Manual precision per class: {}'.format(man_precision))\n",
    "\n",
    "    print('Recall per class: {}'.format(recall))\n",
    "    print('Manual recall per class: {}'.format(man_recall))\n",
    "\n",
    "    print('F1-score per class: {}'.format(f1score))\n",
    "    print('Manual F1-score per class: {}'.format(man_f1score))\n",
    "\n",
    "    print('confusion matrix:\\n {}'.format(cm))\n",
    "    \n",
    "\n",
    "    #F: in the following, we plot the confusion matrix (cm)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=l_names, yticklabels=l_names,\n",
    "           title= 'Confusion matrix',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions (#F: i.e., cells in the confusion matrix) and create text annotations. \n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for w in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, w, format(cm[w, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[w, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "    return accuracy, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4b) \n",
    "Load RF and KNN models saved in .json files in tasks 3c) and 3e) and store into new model objects.\n",
    "Then, perform predictions for the test set and call function *performance_eval()* to evaluate performance of the RF and KNN models\n",
    "\n",
    "Hints:\n",
    "- use *pickle.load* to load .json models\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the distinct labels\n",
    "label_names = list(set(y))\n",
    "print(label_names)\n",
    "\n",
    "#F: the following objects are those where you need to load the pre-saved RF and KNN models\n",
    "newRF = RandomForestClassifier()\n",
    "newKNN = KNeighborsClassifier()\n",
    "\n",
    "print('Evaluating RF performance.....')\n",
    "newRF = pickle.load(open(rfmodelfile, 'rb'))\n",
    "ypredRF = newRF.predict(X_test)\n",
    "accuracy_RF, precision_RF, recall_RF, f1_RF = performance_eval(y_test, ypredRF, label_names)\n",
    "\n",
    "print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "print('Evaluating KNN performance.....')\n",
    "newKNN = pickle.load(open(knnmodelfile, 'rb'))\n",
    "ypredKNN = newKNN.predict(X_test)\n",
    "accuracy_KNN, precision_KNN, recall_KNN, f1_KNN = performance_eval(y_test, ypredKNN, label_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4c) \n",
    "For RF and KNN, compute global precision, recall and F1-score as mean of per-class metrics and plot in 4 separate graphs: \n",
    "1) global metrics (accuracy, precision, recall, F1-score) - bar graph\n",
    "2) precision (global and per-class) - bar-graph + global precision in a horizontal line\n",
    "3) recall (global and per-class) - bar-graph + global recall in a horizontal line\n",
    "4) F1-score (global and per-class) - bar-graph + global F1-score in a horizontal line\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------RF---------------#\n",
    "global_precision_RF = precision_RF.mean()\n",
    "global_recall_RF = recall_RF.mean()\n",
    "global_f1_RF = f1_RF.mean()\n",
    "\n",
    "RF_global = [accuracy_RF, global_precision_RF, global_recall_RF, global_f1_RF]\n",
    "\n",
    "#---------------KNN---------------#\n",
    "global_precision_KNN = precision_KNN.mean()\n",
    "global_recall_KNN = recall_KNN.mean()\n",
    "global_f1_KNN = f1_KNN.mean()\n",
    "\n",
    "KNN_global = [accuracy_KNN, global_precision_KNN, global_recall_KNN, global_f1_KNN]\n",
    "\n",
    "#---------------plots---------------#\n",
    "xRF = np.arange(4)-0.1  # the x locations for the bars in global metrics plot\n",
    "xKNN = np.arange(4)+0.1  # the x locations for the bars in global metrics plot\n",
    "x2RF = np.arange(6)-0.1  # the x locations for the bars in precision/recall/f1-score metrics plot\n",
    "x2KNN = np.arange(6)+0.1  # the x locations for the bars in precision/recall/f1-score metrics plot\n",
    "w = 0.2       # the width of the bars\n",
    "\n",
    "# 1) global metrics\n",
    "plt.bar(xRF, RF_global, width=w, edgecolor='black', color='c', align='center', hatch='///', label='RF')\n",
    "plt.bar(xKNN, KNN_global, width=w, edgecolor='black', color='y', align='center',hatch='---', label='KNN')\n",
    "plt.xticks(xRF+0.1, [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "plt.title('RF & KNN performance metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim([0.5,1.01])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2) precision (global and per-class)\n",
    "plt.bar(x2RF, precision_RF, width=w, edgecolor='black', color='c', align='center', hatch='///', label='RF')\n",
    "plt.bar(x2KNN, precision_KNN, width=w, edgecolor='black', color='y', align='center', hatch='---', label='KNN')\n",
    "plt.plot(x2RF,list((global_precision_RF,)*6), color='c', linestyle='dashed')\n",
    "plt.plot(x2RF,list((global_precision_KNN,)*6), color='y', linestyle='dashed')\n",
    "plt.xticks(x2RF+0.1, label_names)\n",
    "plt.title('RF & KNN precision (global and per-class)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.5,1.01])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 3) recall (global and per-class)\n",
    "plt.bar(x2RF, recall_RF, width=w, edgecolor='black', color='c', align='center', hatch='///', label='RF')\n",
    "plt.bar(x2KNN, recall_KNN, width=w, edgecolor='black', color='y', align='center', hatch='---', label='KNN')\n",
    "plt.plot(x2RF,list((global_recall_RF,)*6), color='c', linestyle='dashed')\n",
    "plt.plot(x2RF,list((global_recall_KNN,)*6), color='y', linestyle='dashed')\n",
    "plt.xticks(x2RF+0.1, label_names)\n",
    "plt.title('RF & KNN recall (global and per-class)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Recall')\n",
    "plt.ylim([0.5,1.01])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 4) f1-score (global and per-class)\n",
    "plt.bar(x2RF, f1_RF, width=w, edgecolor='black', color='c', align='center', hatch='///', label='RF')\n",
    "plt.bar(x2KNN, f1_KNN, width=w, edgecolor='black', color='y', align='center', hatch='---', label='KNN')\n",
    "plt.plot(x2RF,list((global_f1_RF,)*6), color='c', linestyle='dashed')\n",
    "plt.plot(x2RF,list((global_f1_KNN,)*6), color='y', linestyle='dashed')\n",
    "plt.xticks(x2RF+0.1, label_names)\n",
    "plt.title('RF & KNN F1-score (global and per-class)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('F1-score')\n",
    "plt.ylim([0.5,1.01])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CLUSTERING (UNSUPERVISED) PART STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F: check dimensions of current datasets (full, train, test)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5a) \n",
    "Starting from (X,y), above, generate new \"truncated\" dataset by removing all labels different from HW failures (label = 5)\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_keep = [5]\n",
    "label_names = list(set(y)) #we had already used this line\n",
    "\n",
    "#F: initialization\n",
    "X_truncated = X\n",
    "y_truncated = y\n",
    "\n",
    "\n",
    "#F: now we remove all data points with label != labels_to_keep\n",
    "\n",
    "for el in label_names:\n",
    "    if el not in labels_to_keep:\n",
    "        X_truncated = np.delete(X_truncated,np.where(y_truncated==el),0)\n",
    "        y_truncated = np.delete(y_truncated,np.where(y_truncated==el),0)\n",
    "\n",
    "print(X_truncated.shape)\n",
    "print(y_truncated.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5b) \n",
    "Instantiate and fit a PCA object on the truncated dataset *X_truncated*, then plot the explained variance for all components separately and cumulatively (i.e., adding one component at a time in the dataset) \n",
    "\n",
    "Hints: \n",
    "- use *PCA* and *PCA.fit* from *sklearn.decomposition* to instantiate and fit PCA object\n",
    "- use *explained_variance_ratio_* to retrieve explained variance\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=35)\n",
    "pca.fit(X_truncated)\n",
    "print('Variance represented by each component, %:')\n",
    "print(np.round(pca.explained_variance_ratio_, 3) * 100)\n",
    "\n",
    "components = len(pca.explained_variance_ratio_)\n",
    "plt.bar(range(1,components+1), pca.explained_variance_ratio_ * 100)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Per-component explained variance (%)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1,components+1), np.cumsum(pca.explained_variance_ratio_ * 100))\n",
    "plt.xlabel('Number of components included')\n",
    "plt.ylabel('Cumulative explained variance (%)')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5c) \n",
    "Consider the cases of 2 and 3 PCA components to visualize the (transformed) dataset via a scatterplot of the (transformed) features in 2D and 3D graphs\n",
    "\n",
    "Hints: \n",
    "- use *PCA.fit_transform* from *sklearn.decomposition* to transform the dataset into a 2D or 3D features space\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [2, 3]:\n",
    "    \n",
    "    pca = PCA(i)\n",
    "    X_PCA = pca.fit_transform(X_truncated)\n",
    "        \n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "            \n",
    "    if i == 2:\n",
    "        plt.scatter(X_PCA[:,0], X_PCA[:,1])\n",
    "                \n",
    "    elif i == 3:\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        ax.scatter(X_PCA[:,0], X_PCA[:,1], X_PCA[:,2])\n",
    "                \n",
    "    plt.title('{}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5d) \n",
    "Perform clustering on dataset X_truncated with number of clusters k in range(2, 21) and considering kmeans algorithm.\n",
    "Plot inertia and silhouette for each value of k\n",
    "\n",
    "Hints: \n",
    "- use *cluster* from *sklearn* to instantiate *KMeans* object and *inertia_* attribute to retrieve inertia from it\n",
    "- use *silhouette_score()* and *labels_* attribute to retrieve silhouette\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = {}\n",
    "silhouette = {}\n",
    "for k in range(2, 21):\n",
    "    kmeans = cluster.KMeans(n_clusters=k, max_iter=1000).fit(X_truncated)\n",
    "    inertia[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their cluster center\n",
    "    silhouette[k] = silhouette_score(X_truncated, kmeans.labels_) \n",
    "plt.figure()\n",
    "plt.plot(list(inertia.keys()), list(inertia.values()))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(silhouette.keys()), list(silhouette.values()))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Silhouette\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5e) \n",
    "Repeat task 5d) considering the PCA-modified dataset with a number of components that retains at least 90% variance of the original dataset X_truncated\n",
    "\n",
    "Hint: \n",
    "- check output of task 5b) to identify the number of components to use\n",
    "- take inspiration from task 5c) to apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F: for each number of cluster (k in k-means algorithm) store inertia and silhouette in the following dictionaries\n",
    "inertia = {}\n",
    "silhouette = {}\n",
    "############# ADD YOUR CODE BELOW #############\n",
    "\n",
    "numcomponents = 10\n",
    "pca = PCA(numcomponents)\n",
    "X_PCA = pca.fit_transform(X_truncated)\n",
    "\n",
    "for k in range(2, 21):\n",
    "    km = cluster.KMeans(n_clusters=k, max_iter=1000).fit(X_PCA)\n",
    "    inertia[k] = km.inertia_ # Inertia: Sum of distances of samples to their cluster center\n",
    "    silhouette[k] = silhouette_score(X_PCA, km.labels_) \n",
    "    \n",
    "\n",
    "########################################################################\n",
    "plt.figure()\n",
    "plt.plot(list(inertia.keys()), list(inertia.values()), color='r')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia (with {} components)\".format(numcomponents))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(silhouette.keys()), list(silhouette.values()), color='r')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Silhouette (with {} components)\".format(numcomponents))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6a)\n",
    "Generate a new \"truncated\" dataset taking only labels 1=Extra-attenuation and 4=Self-interference from the original dataset. Then, perform kmeans clustering with the new dataset and considering PCA with 10 components and k in range(2, 10)\n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_keep = [1,4]\n",
    "\n",
    "#F: initialization (use the names below for the new dataset\n",
    "X_truncated = X\n",
    "y_truncated = y\n",
    "\n",
    "for el in label_names:\n",
    "    if el not in labels_to_keep:\n",
    "        X_truncated = np.delete(X_truncated,np.where(y_truncated==el),0)\n",
    "        y_truncated = np.delete(y_truncated,np.where(y_truncated==el),0)\n",
    "\n",
    "print(X_truncated.shape)\n",
    "print(y_truncated.shape)\n",
    "\n",
    "\n",
    "numcomponents = 10\n",
    "pca = PCA(numcomponents)\n",
    "X_PCA = pca.fit_transform(X_truncated)\n",
    "\n",
    "inertia = {}\n",
    "silhouette = {}\n",
    "for k in range(2, 10):\n",
    "    km = cluster.KMeans(n_clusters=k, max_iter=1000).fit(X_PCA)\n",
    "    inertia[k] = km.inertia_ # Inertia: Sum of distances of samples to their cluster center\n",
    "    silhouette[k] = silhouette_score(X_PCA, km.labels_) \n",
    "plt.figure()\n",
    "plt.plot(list(inertia.keys()), list(inertia.values()))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia (with {} components)\".format(numcomponents))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(silhouette.keys()), list(silhouette.values()))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Silhouette (with {} components)\".format(numcomponents))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6b) \n",
    "Perform kmeans clustering of the truncated dataset of task 6a, considering k=2 and 10 PCA components. Then assign labels to data points and compare this partition with the ground truth (labels 1,4 in y_truncated) in terms of *rand_score*, *homogeneity_score* and *completeness_score*\n",
    "\n",
    "Hints: \n",
    "- use *sklearn.metrics* to retrieve the above metrics. See documentation at \n",
    "https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation \n",
    "\n",
    "(code is already given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = cluster.KMeans(n_clusters=2, max_iter=1000).fit(X_PCA)\n",
    "\n",
    "y_pred = km.fit_predict(X_PCA)\n",
    "\n",
    "rand = round(mt.rand_score(y_truncated, y_pred), 2)\n",
    "homog = round(mt.homogeneity_score(y_truncated, y_pred), 2) # 1 if each cluster contains only members of a single class\n",
    "complet = round(mt.completeness_score(y_truncated, y_pred), 2) # 1 if all members of a given class are assigned to the same cluster\n",
    "\n",
    "print('Rand_score (0; 1): ' +str(rand))\n",
    "print('Homogeneity (0; 1): ' +str(homog))\n",
    "print('Completeness (0; 1): ' +str(complet))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
